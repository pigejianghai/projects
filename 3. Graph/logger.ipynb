{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available github public repositories:\n",
    "1. GCN pytorch==1.0, python==3.7\n",
    "2. GIN pytorch==1.6, python==3.7.3\n",
    "3. GAT pytorch==1.7, python==3.8\n",
    "\n",
    "Hence, we set the virtual environment (pytorch==1.8, python==3.8):\n",
    "### Name                    Version                   Build  Channel\n",
    "_libgcc_mutex             0.1                        main\\\n",
    "_openmp_mutex             5.1                       1_gnu\\\n",
    "aiohappyeyeballs          2.4.4                    pypi_0    pypi\\\n",
    "aiohttp                   3.10.11                  pypi_0    pypi\\\n",
    "aiosignal                 1.3.1                    pypi_0    pypi\\\n",
    "async-timeout             5.0.1                    pypi_0    pypi\\\n",
    "attrs                     25.3.0                   pypi_0    pypi\\\n",
    "ca-certificates           2025.2.25            h06a4308_0\\\n",
    "certifi                   2025.1.31                pypi_0    pypi\\\n",
    "charset-normalizer        3.4.1                    pypi_0    pypi\n",
    "dataclasses               0.6                      pypi_0    pypi\n",
    "frozenlist                1.5.0                    pypi_0    pypi\n",
    "fsspec                    2025.3.0                 pypi_0    pypi\n",
    "future                    1.0.0                    pypi_0    pypi\n",
    "googledrivedownloader     1.1.0                    pypi_0    pypi\n",
    "idna                      3.10                     pypi_0    pypi\n",
    "isodate                   0.7.2                    pypi_0    pypi\n",
    "jinja2                    3.1.6                    pypi_0    pypi\n",
    "joblib                    1.4.2                    pypi_0    pypi\n",
    "ld_impl_linux-64          2.40                 h12ee557_0\n",
    "libffi                    3.4.4                h6a678d5_1\n",
    "libgcc-ng                 11.2.0               h1234567_1\n",
    "libgomp                   11.2.0               h1234567_1\n",
    "libstdcxx-ng              11.2.0               h1234567_1\n",
    "markupsafe                2.1.5                    pypi_0    pypi\n",
    "multidict                 6.1.0                    pypi_0    pypi\n",
    "ncurses                   6.4                  h6a678d5_0\n",
    "networkx                  3.1                      pypi_0    pypi\n",
    "openssl                   3.0.16               h5eee18b_0\n",
    "pandas                    2.0.3                    pypi_0    pypi\n",
    "pillow                    10.4.0                   pypi_0    pypi\n",
    "pip                       24.2             py38h06a4308_0\n",
    "propcache                 0.2.0                    pypi_0    pypi\n",
    "psutil                    7.0.0                    pypi_0    pypi\n",
    "python                    3.8.20               he870216_0\n",
    "python-dateutil           2.9.0.post0              pypi_0    pypi\n",
    "pytz                      2025.1                   pypi_0    pypi\n",
    "pyyaml                    6.0.2                    pypi_0    pypi\n",
    "rdflib                    7.1.3                    pypi_0    pypi\n",
    "readline                  8.2                  h5eee18b_0\n",
    "requests                  2.32.3                   pypi_0    pypi\n",
    "scikit-learn              1.3.2                    pypi_0    pypi\n",
    "scipy                     1.10.1                   pypi_0    pypi\n",
    "setuptools                75.1.0           py38h06a4308_0\n",
    "six                       1.17.0                   pypi_0    pypi\n",
    "sqlite                    3.45.3               h5eee18b_0\n",
    "threadpoolctl             3.5.0                    pypi_0    pypi\n",
    "tk                        8.6.14               h39e8969_0\n",
    "torch                     1.8.0                    pypi_0    pypi\n",
    "torch-cluster             1.5.9                    pypi_0    pypi\n",
    "torch-geometric           2.0.0                    pypi_0    pypi\n",
    "torch-scatter             2.0.7                    pypi_0    pypi\n",
    "torch-sparse              0.6.10                   pypi_0    pypi\n",
    "torch-spline-conv         1.2.1                    pypi_0    pypi\n",
    "torchaudio                0.8.0                    pypi_0    pypi\n",
    "torchvision               0.9.0                    pypi_0    pypi\n",
    "tqdm                      4.67.1                   pypi_0    pypi\n",
    "typing-extensions         4.12.2                   pypi_0    pypi\n",
    "tzdata                    2025.1                   pypi_0    pypi\n",
    "urllib3                   2.2.3                    pypi_0    pypi\n",
    "wheel                     0.44.0           py38h06a4308_0\n",
    "xz                        5.6.4                h5eee18b_1\n",
    "yacs                      0.1.8                    pypi_0    pypi\n",
    "yarl                      1.15.2                   pypi_0    pypi\n",
    "zlib                      1.2.13               h5eee18b_1\n",
    "\n",
    "Notably, the torch-geometric==2.0 torch-cluster==1.5.9 torch-scatter==2.0.7 torch-sparse==0.6.10 torch-spline-conv==1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset cora, citeseer, pubmed download with torch_geometric.datasets.Planetoid\n",
    "url = \n",
    "Data preprocess and fixed splitted (48%/32%/20%) on dataset cora, citeseer, pubmed"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data manually with original .npz file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset chameleon, squirrel, crocodile download with torch_geometric.datasets.WikipediaNetwork\n",
    "original .npz file: url = 'https://graphmining.ai/datasets/ptg/wiki'"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png) chameleon with 1 case in class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from torch_geometric.utils import subgraph\n",
    "\n",
    "def load_heterophilous_dataset(name, data_dir='/data/Data2/jianghai/dataset'):\n",
    "    # ... [previous loading code] ...\n",
    "    raw_data = np.load(os.path.join(data_dir, f'{name}.npz'))\n",
    "    \n",
    "    data = Data(\n",
    "        x=torch.tensor(raw_data['features'], dtype=torch.float),\n",
    "        edge_index=torch.tensor(raw_data['edges'].T, dtype=torch.long),\n",
    "        y=torch.tensor(raw_data['label'], dtype=torch.long)\n",
    "    )  # Original data creation\n",
    "    \n",
    "    # Add class removal here\n",
    "    if name == 'chameleon':\n",
    "        class_to_remove = 5\n",
    "        mask = data.y != class_to_remove\n",
    "        data = data.subgraph(mask)\n",
    "    \n",
    "    # Continue with splitting\n",
    "    indices = np.arange(data.num_nodes)\n",
    "    labels = data.y.numpy()\n",
    "    \n",
    "    # Stratified splitting (48% train, 32% val, 20% test)\n",
    "    # First split: train (48%) vs temp (52%)\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        indices,\n",
    "        train_size=0.48,\n",
    "        stratify=labels,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Second split: val (32% of total) and test (20% of total)\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx,\n",
    "        test_size=0.3846,  # 0.20 / 0.52 ≈ 0.3846\n",
    "        stratify=labels[temp_idx],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create mask tensors\n",
    "    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.train_mask[train_idx] = True\n",
    "\n",
    "    data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.val_mask[val_idx] = True\n",
    "\n",
    "    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.test_mask[test_idx] = True\n",
    "    \n",
    "    return data\n",
    "\n",
    "def remove_class_and_clean(data, class_to_remove):\n",
    "    # Create mask for nodes to keep\n",
    "    keep_mask = data.y != class_to_remove\n",
    "    \n",
    "    # Filter nodes and edges using subgraph\n",
    "    filtered_data = data.subgraph(keep_mask)\n",
    "    \n",
    "    # Re-map remaining class labels if needed (optional)\n",
    "    # filtered_data.y = torch.unique(filtered_data.y, return_inverse=True)[1]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Load original dataset (using previous loading code)\n",
    "chameleon_data = load_heterophilous_dataset('chameleon')\n",
    "squirrel_data = load_heterophilous_dataset('squirrel')\n",
    "\n",
    "# Before removal stats\n",
    "print(\"Chameleon dataset:\")\n",
    "print(f\"Nodes: {chameleon_data.num_nodes}\")\n",
    "print(f\"Edges: {chameleon_data.edge_index.shape[1]}\")\n",
    "print(\"Class distribution:\", torch.bincount(chameleon_data.y))\n",
    "\n",
    "print(\"Squirrel dataset:\")\n",
    "print(f\"Nodes: {squirrel_data.num_nodes}\")\n",
    "print(f\"Edges: {squirrel_data.edge_index.shape[1]}\")\n",
    "print(\"Class distribution:\", torch.bincount(squirrel_data.y))\n",
    "\n",
    "# Remove class 5 nodes\n",
    "# class_to_remove = 5\n",
    "# filtered_data = remove_class_and_clean(chameleon_data, class_to_remove)\n",
    "\n",
    "# # After removal stats\n",
    "# print(\"\\nFiltered dataset:\")\n",
    "# print(f\"Nodes: {filtered_data.num_nodes}\")\n",
    "# print(f\"Edges: {filtered_data.edge_index.shape[1]}\")\n",
    "# print(\"Remaining classes:\", torch.unique(filtered_data.y))\n",
    "# print(\"New class distribution:\", torch.bincount(filtered_data.y))\n",
    "\n",
    "# # Verify splits after removal\n",
    "# print(\"\\nUpdated splits:\")\n",
    "# print(f\"Train: {filtered_data.train_mask.sum().item()} nodes\")\n",
    "# print(f\"Val: {filtered_data.val_mask.sum().item()} nodes\")\n",
    "# print(f\"Test: {filtered_data.test_mask.sum().item()} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "root = '/data/Data2/jianghai/dataset'\n",
    "cora = Planetoid(root=root, name='cora'.capitalize(), split='random', \n",
    "                 transform=NormalizeFeatures(), \n",
    "                 num_train_per_class=107, num_val=499, num_test=312)\n",
    "\n",
    "citeseer = Planetoid(root=root, name='citeseer'.capitalize(), split='random', \n",
    "                     transform=NormalizeFeatures(), \n",
    "                     num_train_per_class=129, num_val=518, num_test=324)\n",
    "\n",
    "pubmed = Planetoid(root=root, name='Pubmed'.capitalize(), split='random', \n",
    "                   transform=NormalizeFeatures(), \n",
    "                   num_train_per_class=250, num_val=499, num_test=312)\n",
    "\n",
    "def process_data(data):\n",
    "    # Convert to undirected graph (if not already)\n",
    "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
    "    \n",
    "    # Remove duplicate edges\n",
    "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
    "    \n",
    "    # Add self-loops\n",
    "    data.edge_index = add_self_loops(data.edge_index)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def add_self_loops(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max().item() + 1\n",
    "    loop_index = torch.arange(0, num_nodes, dtype=torch.long).view(1, -1).repeat(2, 1)\n",
    "    return torch.cat([edge_index, loop_index], dim=1)\n",
    "\n",
    "def print_stats(dataset):\n",
    "    data = dataset[0]\n",
    "    data = process_data(data)\n",
    "    print(f\"\\n{dataset.name} Dataset:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total nodes: {data.num_nodes}\")\n",
    "    print(f\"Edges (directed): {data.edge_index.shape[1]//2}\")\n",
    "    print(f\"Features per node: {data.num_features}\")\n",
    "    print(f\"Classes: {dataset.num_classes}\")\n",
    "    print(f\"Training nodes: {data.train_mask.sum().item()}\")\n",
    "    print(f\"Validation nodes: {data.val_mask.sum().item()}\")\n",
    "    print(f\"Test nodes: {data.test_mask.sum().item()}\")\n",
    "    print(f\"Class distribution:\\n{torch.bincount(data.y)}\")\n",
    "    print(f\"Average node degree: {data.edge_index.shape[1] // data.num_nodes:.2f}\")\n",
    "    print(f\"Contains self-loops: {data.edge_index[0] == data.edge_index[1]}.any()\")\n",
    "    print(f\"Is undirected: {data.is_undirected()}\")\n",
    "    \n",
    "print_stats(cora)\n",
    "print_stats(citeseer)\n",
    "print_stats(pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Training GCN on Cora\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianghai/.conda/envs/UL/lib/python3.9/site-packages/torch_geometric/io/fs.py:229: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([GlobalStorage])` to allowlist this global.\n",
      "  warnings.warn(f\"{warn_msg} Please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: 0.7514, Train: 0.9105, Val: 0.8236, Test: 0.8077\n",
      "Epoch: 100, Loss: 0.4648, Train: 0.9199, Val: 0.8236, Test: 0.8237\n",
      "Epoch: 150, Loss: 0.3802, Train: 0.9252, Val: 0.8257, Test: 0.8301\n",
      "Epoch: 200, Loss: 0.3606, Train: 0.9426, Val: 0.8196, Test: 0.8301\n",
      "\n",
      "Best validation accuracy: 0.8357\n",
      "Corresponding test accuracy: 0.8365\n",
      "\n",
      "----------------------------------------\n",
      "Training GIN on Cora\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.0191, Train: 0.9973, Val: 0.7395, Test: 0.7276\n",
      "Epoch: 100, Loss: 0.0208, Train: 0.9987, Val: 0.7114, Test: 0.6891\n",
      "Epoch: 150, Loss: 0.0115, Train: 0.9987, Val: 0.7154, Test: 0.6891\n",
      "Epoch: 200, Loss: 0.0079, Train: 0.9987, Val: 0.7234, Test: 0.7083\n",
      "\n",
      "Best validation accuracy: 0.8036\n",
      "Corresponding test accuracy: 0.7628\n",
      "\n",
      "----------------------------------------\n",
      "Training GAT on Cora\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.7098, Train: 0.9306, Val: 0.8397, Test: 0.8397\n",
      "Epoch: 100, Loss: 0.5927, Train: 0.9479, Val: 0.8477, Test: 0.8462\n",
      "Epoch: 150, Loss: 0.6131, Train: 0.9399, Val: 0.8697, Test: 0.8558\n",
      "Epoch: 200, Loss: 0.6273, Train: 0.9466, Val: 0.8357, Test: 0.8301\n",
      "\n",
      "Best validation accuracy: 0.8818\n",
      "Corresponding test accuracy: 0.8494\n",
      "\n",
      "----------------------------------------\n",
      "Training GCN on Citeseer\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 1.0017, Train: 0.8333, Val: 0.7394, Test: 0.7130\n",
      "Epoch: 100, Loss: 0.6773, Train: 0.8721, Val: 0.7220, Test: 0.6975\n",
      "Epoch: 150, Loss: 0.5490, Train: 0.8953, Val: 0.7143, Test: 0.6944\n",
      "Epoch: 200, Loss: 0.4874, Train: 0.9109, Val: 0.7143, Test: 0.6975\n",
      "\n",
      "Best validation accuracy: 0.7432\n",
      "Corresponding test accuracy: 0.7222\n",
      "\n",
      "----------------------------------------\n",
      "Training GIN on Citeseer\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.0271, Train: 0.9871, Val: 0.6486, Test: 0.6636\n",
      "Epoch: 100, Loss: 0.0209, Train: 0.9922, Val: 0.6622, Test: 0.6944\n",
      "Epoch: 150, Loss: 0.0297, Train: 0.9922, Val: 0.6120, Test: 0.6759\n",
      "Epoch: 200, Loss: 0.0225, Train: 0.9922, Val: 0.5965, Test: 0.6389\n",
      "\n",
      "Best validation accuracy: 0.6718\n",
      "Corresponding test accuracy: 0.7099\n",
      "\n",
      "----------------------------------------\n",
      "Training GAT on Citeseer\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.8982, Train: 0.8708, Val: 0.7027, Test: 0.6975\n",
      "Epoch: 100, Loss: 0.7891, Train: 0.8850, Val: 0.7104, Test: 0.7222\n",
      "Epoch: 150, Loss: 0.7678, Train: 0.8992, Val: 0.7066, Test: 0.7253\n",
      "Epoch: 200, Loss: 0.7639, Train: 0.8979, Val: 0.7066, Test: 0.7160\n",
      "\n",
      "Best validation accuracy: 0.7510\n",
      "Corresponding test accuracy: 0.7377\n",
      "\n",
      "----------------------------------------\n",
      "Training GCN on Pubmed\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.4612, Train: 0.8813, Val: 0.7956, Test: 0.8750\n",
      "Epoch: 100, Loss: 0.3656, Train: 0.9040, Val: 0.8257, Test: 0.8846\n",
      "Epoch: 150, Loss: 0.3297, Train: 0.9107, Val: 0.8216, Test: 0.8750\n",
      "Epoch: 200, Loss: 0.2960, Train: 0.9173, Val: 0.8297, Test: 0.8718\n",
      "\n",
      "Best validation accuracy: 0.8337\n",
      "Corresponding test accuracy: 0.8654\n",
      "\n",
      "----------------------------------------\n",
      "Training GIN on Pubmed\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.0172, Train: 1.0000, Val: 0.8016, Test: 0.8269\n",
      "Epoch: 100, Loss: 0.0063, Train: 0.9987, Val: 0.7695, Test: 0.8173\n",
      "Epoch: 150, Loss: 0.0343, Train: 0.9573, Val: 0.7756, Test: 0.7660\n",
      "Epoch: 200, Loss: 0.0039, Train: 1.0000, Val: 0.7655, Test: 0.7724\n",
      "\n",
      "Best validation accuracy: 0.8277\n",
      "Corresponding test accuracy: 0.8462\n",
      "\n",
      "----------------------------------------\n",
      "Training GAT on Pubmed\n",
      "----------------------------------------\n",
      "Epoch: 050, Loss: 0.4697, Train: 0.8947, Val: 0.8477, Test: 0.8013\n",
      "Epoch: 100, Loss: 0.4795, Train: 0.9120, Val: 0.8397, Test: 0.8269\n",
      "Epoch: 150, Loss: 0.4584, Train: 0.8933, Val: 0.8116, Test: 0.8013\n",
      "Epoch: 200, Loss: 0.4743, Train: 0.8893, Val: 0.8096, Test: 0.7821\n",
      "\n",
      "Best validation accuracy: 0.8537\n",
      "Corresponding test accuracy: 0.8237\n",
      "\n",
      "Final Results:\n",
      "\n",
      "Cora:\n",
      "GCN: 0.8365\n",
      "GIN: 0.7628\n",
      "GAT: 0.8494\n",
      "\n",
      "Citeseer:\n",
      "GCN: 0.7222\n",
      "GIN: 0.7099\n",
      "GAT: 0.7377\n",
      "\n",
      "Pubmed:\n",
      "GCN: 0.8654\n",
      "GIN: 0.8462\n",
      "GAT: 0.8237\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GINConv, GATConv\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.nn import Linear, ModuleList, Sequential, ReLU, BatchNorm1d\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 200\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "hidden_dim = 64\n",
    "dropout = 0.5\n",
    "\n",
    "# Random Seed\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Load dataset ['cora', 'citeseer', 'Pubmed']\n",
    "def load_dataset(name):\n",
    "    root = '/data/Data2/jianghai/dataset'\n",
    "    if name == 'cora':\n",
    "        cora = Planetoid(root=root, name='cora'.capitalize(), split='random', \n",
    "                        transform=NormalizeFeatures(), \n",
    "                        num_train_per_class=107, num_val=499, num_test=312)\n",
    "        return cora\n",
    "    elif name == 'citeseer':\n",
    "        citeseer = Planetoid(root=root, name='citeseer'.capitalize(), split='random', \n",
    "                            transform=NormalizeFeatures(), \n",
    "                            num_train_per_class=129, num_val=518, num_test=324)\n",
    "        return citeseer\n",
    "    elif name == 'pubmed':\n",
    "        pubmed = Planetoid(root=root, name='Pubmed'.capitalize(), split='random', \n",
    "                        transform=NormalizeFeatures(), \n",
    "                        num_train_per_class=250, num_val=499, num_test=312)\n",
    "        return pubmed\n",
    "    else:\n",
    "        print('Dataset do not exists!')\n",
    "\n",
    "\n",
    "\n",
    "# Model definitions\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.mlp1 = Sequential(\n",
    "            Linear(num_features, hidden_dim),\n",
    "            BatchNorm1d(hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "        \n",
    "        self.mlp2 = Sequential(\n",
    "            Linear(hidden_dim, hidden_dim),\n",
    "            BatchNorm1d(hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        self.conv2 = GINConv(self.mlp2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(\n",
    "            num_features, \n",
    "            hidden_dim, \n",
    "            heads=8, \n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.conv2 = GATConv(\n",
    "            hidden_dim * 8, \n",
    "            num_classes, \n",
    "            heads=1, \n",
    "            concat=False,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Training and evaluation\n",
    "def train(model, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        acc = (pred[mask] == data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "def run_experiment(dataset_name, model_type):\n",
    "    # Load data\n",
    "    if dataset_name in ['cora', 'citeseer', 'pubmed']:\n",
    "        dataset = load_dataset(dataset_name)\n",
    "    else:\n",
    "        dataset = load_heterophilous_dataset(dataset_name)\n",
    "    data = dataset[0].to(device)\n",
    "    \n",
    "    # Initialize model\n",
    "    if model_type == 'gcn':\n",
    "        model = GCN(dataset.num_features, dataset.num_classes).to(device)\n",
    "    elif model_type == 'gin':\n",
    "        model = GIN(dataset.num_features, dataset.num_classes).to(device)\n",
    "    elif model_type == 'gat':\n",
    "        model = GAT(dataset.num_features, dataset.num_classes).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "    \n",
    "    global optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss = train(model, data)\n",
    "        train_acc, val_acc, test_acc = test(model, data)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "                  f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "                  f'Test: {test_acc:.4f}')\n",
    "    \n",
    "    print(f'\\nBest validation accuracy: {best_val_acc:.4f}')\n",
    "    print(f'Corresponding test accuracy: {best_test_acc:.4f}')\n",
    "    return best_test_acc\n",
    "\n",
    "# Run experiments\n",
    "if __name__ == \"__main__\":\n",
    "    seed_torch(42)\n",
    "    datasets = ['cora', 'citeseer', 'pubmed']\n",
    "    models = ['gcn', 'gin', 'gat']\n",
    "    \n",
    "    results = {}\n",
    "    for dataset in datasets:\n",
    "        results[dataset] = {}\n",
    "        for model in models:\n",
    "            print(f'\\n{\"-\"*40}')\n",
    "            print(f'Training {model.upper()} on {dataset.capitalize()}')\n",
    "            print(f'{\"-\"*40}')\n",
    "            test_acc = run_experiment(dataset, model)\n",
    "            results[dataset][model] = test_acc\n",
    "    \n",
    "    # Print final results\n",
    "    print('\\nFinal Results:')\n",
    "    for dataset in datasets:\n",
    "        print(f'\\n{dataset.capitalize()}:')\n",
    "        for model in models:\n",
    "            print(f'{model.upper()}: {results[dataset][model]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHAMELEON ===\n",
      "\n",
      "Training GCN\n",
      "Epoch: 050, Loss: 0.9400, Train: 0.6639, Val: 0.5810, Test: 0.5482\n",
      "Epoch: 100, Loss: 0.7957, Train: 0.6941, Val: 0.5852, Test: 0.5570\n",
      "Epoch: 150, Loss: 0.7258, Train: 0.7207, Val: 0.5948, Test: 0.5614\n",
      "Epoch: 200, Loss: 0.6924, Train: 0.7317, Val: 0.6044, Test: 0.5768\n",
      "Epoch: 250, Loss: 0.6435, Train: 0.7592, Val: 0.6168, Test: 0.6031\n",
      "Epoch: 300, Loss: 0.6123, Train: 0.7527, Val: 0.6126, Test: 0.5833\n",
      "Epoch: 350, Loss: 0.5523, Train: 0.7830, Val: 0.6277, Test: 0.6096\n",
      "Epoch: 400, Loss: 0.5485, Train: 0.8260, Val: 0.6525, Test: 0.6623\n",
      "Epoch: 450, Loss: 0.5482, Train: 0.8342, Val: 0.6525, Test: 0.6338\n",
      "Epoch: 500, Loss: 0.5294, Train: 0.8269, Val: 0.6415, Test: 0.6447\n",
      "GCN Test Accuracy: 0.6579\n",
      "\n",
      "Training GIN\n",
      "Epoch: 050, Loss: 0.9982, Train: 0.5815, Val: 0.5371, Test: 0.5088\n",
      "Epoch: 100, Loss: 0.7208, Train: 0.7537, Val: 0.6401, Test: 0.6228\n",
      "Epoch: 150, Loss: 0.5605, Train: 0.7885, Val: 0.6401, Test: 0.6360\n",
      "Epoch: 200, Loss: 0.5210, Train: 0.8379, Val: 0.6593, Test: 0.6535\n",
      "Epoch: 250, Loss: 0.4438, Train: 0.8727, Val: 0.6676, Test: 0.6623\n",
      "Epoch: 300, Loss: 0.3769, Train: 0.8828, Val: 0.6593, Test: 0.6798\n",
      "Epoch: 350, Loss: 0.3567, Train: 0.9002, Val: 0.6703, Test: 0.6711\n",
      "Early stopping at epoch 384\n",
      "GIN Test Accuracy: 0.6732\n",
      "\n",
      "Training GAT\n",
      "Epoch: 050, Loss: 2.9671, Train: 0.3059, Val: 0.2885, Test: 0.2478\n",
      "Epoch: 100, Loss: 2.0023, Train: 0.3526, Val: 0.3242, Test: 0.3224\n",
      "Epoch: 150, Loss: 1.8430, Train: 0.3443, Val: 0.3407, Test: 0.3048\n",
      "Epoch: 200, Loss: 1.8642, Train: 0.3434, Val: 0.3269, Test: 0.3092\n",
      "Early stopping at epoch 205\n",
      "GAT Test Accuracy: 0.3443\n",
      "\n",
      "=== SQUIRREL ===\n",
      "\n",
      "Training GCN\n",
      "Epoch: 050, Loss: 1.3007, Train: 0.4655, Val: 0.3816, Test: 0.3766\n",
      "Epoch: 100, Loss: 1.1893, Train: 0.5232, Val: 0.4135, Test: 0.4035\n",
      "Epoch: 150, Loss: 1.1110, Train: 0.5701, Val: 0.4393, Test: 0.4390\n",
      "Epoch: 200, Loss: 1.0864, Train: 0.5933, Val: 0.4555, Test: 0.4380\n",
      "Epoch: 250, Loss: 1.0332, Train: 0.6174, Val: 0.4669, Test: 0.4524\n",
      "Epoch: 300, Loss: 0.9892, Train: 0.6334, Val: 0.4820, Test: 0.4544\n",
      "Epoch: 350, Loss: 0.9882, Train: 0.6514, Val: 0.4748, Test: 0.4582\n",
      "Epoch: 400, Loss: 0.9615, Train: 0.6631, Val: 0.4874, Test: 0.4669\n",
      "Epoch: 450, Loss: 0.9423, Train: 0.6803, Val: 0.4826, Test: 0.4640\n",
      "Epoch: 500, Loss: 0.9106, Train: 0.6787, Val: 0.4940, Test: 0.4640\n",
      "GCN Test Accuracy: 0.4726\n",
      "\n",
      "Training GIN\n",
      "Epoch: 050, Loss: 1.4145, Train: 0.3766, Val: 0.3480, Test: 0.3689\n",
      "Epoch: 100, Loss: 1.2555, Train: 0.4295, Val: 0.3828, Test: 0.4006\n",
      "Epoch: 150, Loss: 1.1860, Train: 0.4764, Val: 0.4189, Test: 0.4323\n",
      "Epoch: 200, Loss: 1.0838, Train: 0.5389, Val: 0.4519, Test: 0.4630\n",
      "Epoch: 250, Loss: 1.0092, Train: 0.5757, Val: 0.4754, Test: 0.4745\n",
      "Epoch: 300, Loss: 0.8807, Train: 0.6502, Val: 0.4772, Test: 0.5168\n",
      "Epoch: 350, Loss: 0.8751, Train: 0.6691, Val: 0.4880, Test: 0.5207\n",
      "Epoch: 400, Loss: 0.7726, Train: 0.7280, Val: 0.5204, Test: 0.5476\n",
      "Epoch: 450, Loss: 0.6899, Train: 0.7981, Val: 0.5547, Test: 0.5572\n",
      "Epoch: 500, Loss: 0.5917, Train: 0.8466, Val: 0.5877, Test: 0.5908\n",
      "GIN Test Accuracy: 0.5821\n",
      "\n",
      "Training GAT\n",
      "Epoch: 050, Loss: 2.1800, Train: 0.2592, Val: 0.2440, Test: 0.2459\n",
      "Epoch: 100, Loss: 1.8483, Train: 0.2544, Val: 0.2314, Test: 0.2392\n",
      "Early stopping at epoch 144\n",
      "GAT Test Accuracy: 0.2651\n",
      "\n",
      "Final Results:\n",
      "\n",
      "CHAMELEON:\n",
      "GCN: 0.6579\n",
      "GIN: 0.6732\n",
      "GAT: 0.3443\n",
      "\n",
      "SQUIRREL:\n",
      "GCN: 0.4726\n",
      "GIN: 0.5821\n",
      "GAT: 0.2651\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GINConv, GATConv\n",
    "from torch.nn import Linear, Sequential, ReLU, BatchNorm1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "\n",
    "# Configuration\n",
    "device = torch.device('cuda:0')\n",
    "epochs = 500\n",
    "lr = 0.005\n",
    "weight_decay = 5e-5\n",
    "hidden_dim = 128\n",
    "dropout = 0.6\n",
    "heads = 8\n",
    "\n",
    "# Load dataset ['chameleon', 'squirrel']\n",
    "def load_heterophilous_dataset(name):\n",
    "    data_dir='/data/Data2/jianghai/dataset'\n",
    "    raw_data = np.load(os.path.join(data_dir, f'{name}.npz'))\n",
    "    \n",
    "    data = Data(\n",
    "        x=torch.tensor(raw_data['features'], dtype=torch.float),\n",
    "        edge_index=torch.tensor(raw_data['edges'].T, dtype=torch.long),\n",
    "        y=torch.tensor(raw_data['label'], dtype=torch.long)\n",
    "    )  # Original data creation\n",
    "    \n",
    "    # Add class removal here\n",
    "    if name == 'chameleon':\n",
    "        class_to_remove = 5\n",
    "        mask = data.y != class_to_remove\n",
    "        data = data.subgraph(mask)\n",
    "    \n",
    "    # Continue with splitting\n",
    "    indices = np.arange(data.num_nodes)\n",
    "    labels = data.y.numpy()\n",
    "    \n",
    "    # Stratified splitting (48% train, 32% val, 20% test)\n",
    "    # First split: train (48%) vs temp (52%)\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        indices,\n",
    "        train_size=0.48,\n",
    "        stratify=labels,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Second split: val (32% of total) and test (20% of total)\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx,\n",
    "        test_size=0.3846,  # 0.20 / 0.52 ≈ 0.3846\n",
    "        stratify=labels[temp_idx],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create mask tensors\n",
    "    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.train_mask[train_idx] = True\n",
    "\n",
    "    data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.val_mask[val_idx] = True\n",
    "\n",
    "    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.test_mask[test_idx] = True\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Model Definitions\n",
    "class GCNHet(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GINHet(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.mlp1 = Sequential(\n",
    "            Linear(num_features, hidden_dim),\n",
    "            BatchNorm1d(hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "        \n",
    "        self.mlp2 = Sequential(\n",
    "            Linear(hidden_dim, hidden_dim),\n",
    "            BatchNorm1d(hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.conv2 = GINConv(self.mlp2)\n",
    "        \n",
    "        self.lin = Linear(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GATHet(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_dim*heads, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.conv3 = GATConv(hidden_dim*heads, num_classes, heads=1, concat=False, dropout=dropout)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train(model, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    return (\n",
    "        pred[data.train_mask].eq(data.y[data.train_mask]).sum().item() / data.train_mask.sum().item(),\n",
    "        pred[data.val_mask].eq(data.y[data.val_mask]).sum().item() / data.val_mask.sum().item(),\n",
    "        pred[data.test_mask].eq(data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    )\n",
    "\n",
    "def run_experiment(dataset_name, model_class):\n",
    "    data = load_heterophilous_dataset(dataset_name).to(device)\n",
    "    num_features = data.x.size(1)\n",
    "    num_classes = data.y.max().item() + 1\n",
    "    \n",
    "    model = model_class(num_features, num_classes).to(device)\n",
    "    global optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    best_val = 0\n",
    "    best_test = 0\n",
    "    patience = 100\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss = train(model, data)\n",
    "        train_acc, val_acc, test_acc = test(model, data)\n",
    "        \n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_test = test_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            \n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "                  f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "    \n",
    "    return best_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "    results = {}\n",
    "    for dataset in ['chameleon', 'squirrel']:\n",
    "        results[dataset] = {}\n",
    "        print(f\"\\n=== {dataset.upper()} ===\")\n",
    "        \n",
    "        for model_name, model_class in [('GCN', GCNHet), ('GIN', GINHet), ('GAT', GATHet)]:\n",
    "            print(f\"\\nTraining {model_name}\")\n",
    "            test_acc = run_experiment(dataset, model_class)\n",
    "            results[dataset][model_name] = test_acc\n",
    "            print(f\"{model_name} Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    for dataset in ['chameleon', 'squirrel']:\n",
    "        print(f\"\\n{dataset.upper()}:\")\n",
    "        for model in ['GCN', 'GIN', 'GAT']:\n",
    "            print(f\"{model}: {results[dataset][model]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
